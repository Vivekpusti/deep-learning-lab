{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNipiUbD/QUi4GWB4M5SdVq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":18,"metadata":{"id":"XbjeJzuyYy_6","executionInfo":{"status":"ok","timestamp":1668536032795,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vansh Shah","userId":"15256688127317884325"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import pandas as pd\n","import numpy as np\n","import time\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OVN2jQOHZPpS","executionInfo":{"status":"ok","timestamp":1668536036811,"user_tz":-330,"elapsed":4019,"user":{"displayName":"Vansh Shah","userId":"15256688127317884325"}},"outputId":"65935d59-0051-41d0-a2f1-d0ee814547fd"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!unzip /content/drive/MyDrive/dl-lab/dataset/stock.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b1kgNFdXZbRW","executionInfo":{"status":"ok","timestamp":1668536056051,"user_tz":-330,"elapsed":19244,"user":{"displayName":"Vansh Shah","userId":"15256688127317884325"}},"outputId":"75c3f9e7-6949-4373-a658-0057a3ba6459"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/dl-lab/dataset/stock.zip\n","replace stock/stock_price.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n","  inflating: stock/stock_price.csv   \n"]}]},{"cell_type":"code","source":["data=pd.read_csv(\"stock/stock_price.csv\")"],"metadata":{"id":"q8YU7SZDY0Rq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["price = data[['Close']]\n","scaler = MinMaxScaler(feature_range=(-1, 1))\n","price['Close'] = scaler.fit_transform(price['Close'].values.reshape(-1,1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbhFJQIWY1fl","executionInfo":{"status":"ok","timestamp":1668534402843,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vansh Shah","userId":"15256688127317884325"}},"outputId":"fca841f6-2fc3-4f91-b756-692e043aa149"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}]},{"cell_type":"code","source":["def split_data(stock, lookback):\n","    data_raw = stock.to_numpy() \n","    data = []\n","    \n","    \n","    for index in range(len(data_raw) - lookback): \n","        data.append(data_raw[index: index + lookback])\n","    \n","    data = np.array(data);\n","    test_set_size = int(np.round(0.2*data.shape[0]));\n","    train_set_size = data.shape[0] - (test_set_size);\n","    \n","    x_train = data[:train_set_size,:-1,:]\n","    y_train = data[:train_set_size,-1,:]\n","    \n","    x_test = data[train_set_size:,:-1]\n","    y_test = data[train_set_size:,-1,:]\n","    \n","    return [x_train, y_train, x_test, y_test]\n","lookback = 20 \n","x_train, y_train, x_test, y_test = split_data(price, lookback)"],"metadata":{"id":"TrzlAE-YY3MJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train = torch.from_numpy(x_train).type(torch.Tensor)\n","x_test = torch.from_numpy(x_test).type(torch.Tensor)\n","y_train_lstm = torch.from_numpy(y_train).type(torch.Tensor)\n","y_test_lstm = torch.from_numpy(y_test).type(torch.Tensor)\n","y_train_gru = torch.from_numpy(y_train).type(torch.Tensor)\n","y_test_gru = torch.from_numpy(y_test).type(torch.Tensor)"],"metadata":{"id":"vhdof5VSY479"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_dim = 1\n","hidden_dim = 32\n","num_layers = 2\n","output_dim = 1\n","num_epochs = 100"],"metadata":{"id":"JMCILCy8ZrH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LSTM(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n","        super(LSTM, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        \n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n","        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n","        out = self.fc(out[:, -1, :]) \n","        return out"],"metadata":{"id":"57bwMNkRZtYx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n","criterion = torch.nn.MSELoss(reduction='mean')\n","optimiser = torch.optim.Adam(model.parameters(), lr=0.01)"],"metadata":{"id":"Jyz_RplSZvXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","hist = np.zeros(num_epochs)\n","start_time = time.time()\n","lstm = []\n","for t in range(num_epochs):\n","    y_train_pred = model(x_train)\n","    loss = criterion(y_train_pred, y_train_lstm)\n","    print(\"Epoch \", t, \"MSE: \", loss.item())\n","    hist[t] = loss.item()\n","    optimiser.zero_grad()\n","    loss.backward()\n","    optimiser.step()\n","    \n","training_time = time.time()-start_time\n","print(\"Training time: {}\".format(training_time))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mD9WiJDJZxE3","executionInfo":{"status":"ok","timestamp":1668534479011,"user_tz":-330,"elapsed":32097,"user":{"displayName":"Vansh Shah","userId":"15256688127317884325"}},"outputId":"c9b2fd68-aa50-49e1-a450-dcfbbea72352"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch  0 MSE:  0.26404842734336853\n","Epoch  1 MSE:  0.17929324507713318\n","Epoch  2 MSE:  0.12140277773141861\n","Epoch  3 MSE:  0.0915011316537857\n","Epoch  4 MSE:  0.13127167522907257\n","Epoch  5 MSE:  0.09386636316776276\n","Epoch  6 MSE:  0.07996277511119843\n","Epoch  7 MSE:  0.08237574994564056\n","Epoch  8 MSE:  0.0841292068362236\n","Epoch  9 MSE:  0.07850369065999985\n","Epoch  10 MSE:  0.06432095170021057\n","Epoch  11 MSE:  0.044905345886945724\n","Epoch  12 MSE:  0.034232351928949356\n","Epoch  13 MSE:  0.04289514943957329\n","Epoch  14 MSE:  0.018786940723657608\n","Epoch  15 MSE:  0.00518542667850852\n","Epoch  16 MSE:  0.017878932878375053\n","Epoch  17 MSE:  0.023922380059957504\n","Epoch  18 MSE:  0.010918916203081608\n","Epoch  19 MSE:  0.0045949979685246944\n","Epoch  20 MSE:  0.009652789682149887\n","Epoch  21 MSE:  0.009723394177854061\n","Epoch  22 MSE:  0.006440335884690285\n","Epoch  23 MSE:  0.006502971518784761\n","Epoch  24 MSE:  0.008578646928071976\n","Epoch  25 MSE:  0.009580004960298538\n","Epoch  26 MSE:  0.00824924185872078\n","Epoch  27 MSE:  0.00527661107480526\n","Epoch  28 MSE:  0.002778845140710473\n","Epoch  29 MSE:  0.0028944481164216995\n","Epoch  30 MSE:  0.005124672781676054\n","Epoch  31 MSE:  0.006111127324402332\n","Epoch  32 MSE:  0.00463426299393177\n","Epoch  33 MSE:  0.002983485348522663\n","Epoch  34 MSE:  0.0026916805654764175\n","Epoch  35 MSE:  0.0031145913526415825\n","Epoch  36 MSE:  0.0031956390012055635\n","Epoch  37 MSE:  0.002764119766652584\n","Epoch  38 MSE:  0.0024264983367174864\n","Epoch  39 MSE:  0.0026590374764055014\n","Epoch  40 MSE:  0.0030410022009164095\n","Epoch  41 MSE:  0.002767743542790413\n","Epoch  42 MSE:  0.0019784884061664343\n","Epoch  43 MSE:  0.0015847000759094954\n","Epoch  44 MSE:  0.0018641053466126323\n","Epoch  45 MSE:  0.002211430110037327\n","Epoch  46 MSE:  0.0021174137946218252\n","Epoch  47 MSE:  0.001801622798666358\n","Epoch  48 MSE:  0.0017338352045044303\n","Epoch  49 MSE:  0.0018241783836856484\n","Epoch  50 MSE:  0.0016698711551725864\n","Epoch  51 MSE:  0.001379722380079329\n","Epoch  52 MSE:  0.001333541702479124\n","Epoch  53 MSE:  0.0015076868003234267\n","Epoch  54 MSE:  0.001590868690982461\n","Epoch  55 MSE:  0.0014579009730368853\n","Epoch  56 MSE:  0.0012795388465747237\n","Epoch  57 MSE:  0.0012399677652865648\n","Epoch  58 MSE:  0.0012860432034358382\n","Epoch  59 MSE:  0.0012673198943957686\n","Epoch  60 MSE:  0.001208003843203187\n","Epoch  61 MSE:  0.001216442440636456\n","Epoch  62 MSE:  0.0012547177029773593\n","Epoch  63 MSE:  0.0012143184430897236\n","Epoch  64 MSE:  0.0011147760087624192\n","Epoch  65 MSE:  0.0010728193446993828\n","Epoch  66 MSE:  0.001114407554268837\n","Epoch  67 MSE:  0.0011422019451856613\n","Epoch  68 MSE:  0.0011025442508980632\n","Epoch  69 MSE:  0.0010553802130743861\n","Epoch  70 MSE:  0.0010482805082574487\n","Epoch  71 MSE:  0.0010471483692526817\n","Epoch  72 MSE:  0.001022857497446239\n","Epoch  73 MSE:  0.0010079951025545597\n","Epoch  74 MSE:  0.0010238596005365252\n","Epoch  75 MSE:  0.00102900224737823\n","Epoch  76 MSE:  0.000998757896013558\n","Epoch  77 MSE:  0.0009733174811117351\n","Epoch  78 MSE:  0.0009781502885743976\n","Epoch  79 MSE:  0.0009848803747445345\n","Epoch  80 MSE:  0.0009738327353261411\n","Epoch  81 MSE:  0.0009630184504203498\n","Epoch  82 MSE:  0.0009621872450225055\n","Epoch  83 MSE:  0.0009551919647492468\n","Epoch  84 MSE:  0.0009406915633007884\n","Epoch  85 MSE:  0.0009373618522658944\n","Epoch  86 MSE:  0.0009437120170332491\n","Epoch  87 MSE:  0.00094085797900334\n","Epoch  88 MSE:  0.0009292569593526423\n","Epoch  89 MSE:  0.0009239298524335027\n","Epoch  90 MSE:  0.000924428750295192\n","Epoch  91 MSE:  0.0009212173754349351\n","Epoch  92 MSE:  0.0009169155382551253\n","Epoch  93 MSE:  0.0009163707145489752\n","Epoch  94 MSE:  0.0009141132468357682\n","Epoch  95 MSE:  0.0009074315312318504\n","Epoch  96 MSE:  0.0009033523965626955\n","Epoch  97 MSE:  0.000904003856703639\n","Epoch  98 MSE:  0.0009027181076817214\n","Epoch  99 MSE:  0.0008982100407592952\n","Training time: 32.20728349685669\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"SNNx-UFvZybN"},"execution_count":null,"outputs":[]}]}